---
layout: post
title: Sampling without replacement with unequal probabilities
date: 2024-08-31
tag: 
   - Surveys
description: I play around with sampling from finite populations with unequal probabilities, where the R sample() function turns out not to work the way I had expected it to.
image: /img/0276-20-10-no-replace.svg
socialimage: https:/freerangestats.info/img/0276-20-10-no-replace.png
category: R
---

## Not proportional to w

A week ago I was surprised to read on [Thomas Lumley's Biased and Inefficient](https://notstatschat.rbind.io/2024/08/26/another-way-to-not-sample-with-replacement/) blog that when using R's `sample()` function without replacement and with unequal probabilities of individual units being sampled:

> What R currently has is sequential sampling: if you give it a set of priorities w it will sample an element with probability proportional to w from the population, remove it from the population, then sample with probability proportional to w from the remaining elements, and so on. This is useful, but a lot of people donâ€™t realise that the probability of element i being sampled is not proportional to w_i

This surprised me profoundly - in the way that Bertrand Russell once wrote in some epistemological context of getting to the bottom of the stairs and finding there was one more stair to go than you realised. That is, I hadn't even been consciously aware of assuming that the probability of element being sampled is proportional to the weight given to it, but certainly if I *had* been asked I would have given the wrong answer ('yes').

Thomas had some examples in his blog but I wanted to see for myself. So I wrote a function to simulate sampling from a small, finite population, with equal or unequal weights. So mostly, I sampled 10 units at a time from a population of 20; and gave them weights from about 0.005 to 0.095 ( a big range). The weights are forced to add up to 1 so they can be easily compared with that element's proportion of the eventual sample of samples. And then I take some thousands of these samples of 10, and look at the proportion of the total collection that is each element. 

In the charts the follow, the brown diagonal line would be where the eventual proportion of element i being sampled is proportional to its weight. First, here is the main situation of concern - unequal weights, sampling without replacement, sample size is quite a big proportion of the population (10 out of 20):

<object type="image/svg+xml" data='/img/0276-20-10-no-replace.svg' width='100%'><img src='/img/0276-20-10-no-replace.png' width='100%'></object>

OK! so we see the elements with low weights get sampled a bit more than naively expected, and the elements with high weights a bit less.

Just to check I'm not dreaming, here's the same simulation but this time we are sampling *with* replacement. Now, everything works as intuitively might be expected, the eventual proportion in our sample of samples is exactly matched to the original weights:

<object type="image/svg+xml" data='/img/0276-20-10-replace.svg' width='100%'><img src='/img/0276-20-10-replace.png' width='100%'></object>

Here's the code for that function and those two runs of it.

{% highlight R lineanchors %}
library(tidyverse)
library(glue)

compare_ppswor <- function(n = 10,
                           N = 20,
                           replace = FALSE,
                           reps = 1e5,
                           prob = 1:N / sum(1:N),
                           FUN = sample){

  x <- paste0("unit", 1:N)
  x <- factor(x, levels = x)
  prob <- prob / sum(prob)
  
  
  samples <- lapply(rep(n, reps), function(size){
    FUN(x, size = size, prob = prob, replace = replace)
    })
  
  s <- ifelse(replace, 'with replacement', 'without replacement')
  m <- ifelse(identical(FUN, sample), "R's native `sample()` function.", 
                                      "experimental function based on Brewer (1975).")
  
  p <- tibble(
    original = prob,
    selected = as.numeric(table(unlist(samples))) / (reps * n)
  )  |>
    ggplot(aes(x = original, y = selected)) +
    geom_abline(slope = 1 , intercept = 0, colour = "orange") +
    geom_point(colour = "steelblue") +
    labs(x = "Original 'probability' or weight",
         y = "Actual propoinion of selection",
         subtitle = glue("Population of {N}, sample size {n}, sampling {s}.\nUsing {m}"),
         title = "Use of `sample()` with unequal probabilities of sampling") +
    coord_equal() 
  
  return(p)
}

compare_ppswor()
compare_ppswor(replace = TRUE)
{% endhighlight %}

When the sample is a smaller proportion of a population, the no-replacement discrepancy is less, as seen in these examples with population sizes of 50 and 250.  
<object type="image/svg+xml" data='/img/0276-50-10-no-replace.svg' width='100%'><img src='/img/0276-50-10-no-replace.png' width='100%'></object>

<object type="image/svg+xml" data='/img/0276-250-10-no-replace.svg' width='100%'><img src='/img/0276-250-10-no-replace.png' width='100%'></object>

At the extreme, if the sample size is the same size as the population (20 each in the simulation below), then of course, all samples without replacement are identical to the population, so it is impossible for the end proportion to be anything other than 1/N each:
<object type="image/svg+xml" data='/img/0276-20-20-no-replace.svg' width='100%'><img src='/img/0276-20-20-no-replace.png' width='100%'></object>

## Brewer's 1975 algorithm
Thomas was writing because there are plans to change this behaviour of `sample()`, or at least add an option to change it, so instead the eventual proportion of samples containing an element will be proportional to the weight even when sampling with unequal probabilities and without replacement. The method that is going to be implemented in R (written in C of course before being hooked into R - it's an inherently iterative thing that will only be efficient in compiled code) is based on a method published way back in 1975 by Ken Brewer. 

An aside - I had the privilege and pleasure to be taught sampling by Professor Brewer back in the 1990s at the Australian National Universitiy - at least it was a pleasure at the time (sheer entertainment value as well as the pleasure of witnessing someone who was a virtuoso in the subject matter, master of the craft of sampling), and I now belatedly realise what a privilege it was. I do think he struggled with us students though; one of my vivid memories of my whole education at ANU was of him speechless when some of the less mathematically inclined asked him to explain what an equation taking up a fair proportion of the blackboard "means" - "Means? means? it means what it says!" 

I don't have easy access to the 1975 paper but I found a very interesting [question and answers apparently relating to it on Cross-Validated](https://stats.stackexchange.com/questions/110178/brewers-method-for-sampling-with-unequal-probabilities-with-n2). From that discussion and reading the part of the SAS manual referred to, it sounds like SAS implements the algorithm only for when the sample in a given strata is 2, but Brewer was able to generalise his method to larger samples. The answer given by the ever-reliable StasK seems pretty clear on how this is done, so presuming he got it right I had a go at implementing this method into R, with code below in the form of two functions `P()` and `sample_unequal()`:

{% highlight R lineanchors %}

#' @param p probabilities of remaining units
#' @param n total sample size
#' @param k which unit this is for the sampling of
P <- function(p, n, k){
  r <- n - k + 1
  D <- sum((p * (1 - p)) / (1 - r * p))
  new_p <- p * (1 - p) / (D * (1 - r * p))
  return(new_p)
}

sample_unequal <- function(x, size, prob, replace = FALSE, keep = FALSE){

  if(size > length(x)){
    stop("Sample size cannot be larger than the population of units")
  }
  
  if(replace){
    stop("Only sampling without replacement implemented at this point")
  }
  
  if(size > (1 / max(prob))){
    stop(glue("Sample size ({size}) cannot be larger than 1 / max(prob) (which is {1 / max(prob)})"))
  }
  
  d <- tibble(x, prob)
  
  the_sample <- x[NULL]
  remnants <- x
  remnant_p <- prob
  
  for(k in 1:size){
    new_p <- P(remnant_p, size, k)
    
    if(keep){
      d2 <- tibble(x = remnants, prob = new_p)
      names(d2)[2] <- paste0("k", k)
      d <- d |>
        left_join(d2, by = "x")
    }
    
    if(min(new_p) < 0){
      warning("Some negative probabilities returned")
      new_p <- pmax(0, new_p)
    }
    
    latest_sample <- sample(remnants, size = 1, prob = new_p)
    which_chosen <- which(remnants == latest_sample)
    remnants <- remnants[-which_chosen]
    remnant_p <- remnant_p[-which_chosen]
    the_sample <- c(the_sample, latest_sample)
    
      }
  
  if(keep){
    return(list(the_sample = the_sample, d = d)) 
  } else {
    return(the_sample)
  }
}  
{% endhighlight %}

I'm not guaranteeing I got it right - feedback is welcome.

Of course, I designed this to be plugged into my function I made earlier for comparing eventual sample proportions to the weights given, so with `compare_ppswor(FUN = sample_unequal, reps = 10000)` I can get this comparison:

<object type="image/svg+xml" data='/img/0276-20-10-no-replace-brewer.svg' width='100%'><img src='/img/0276-20-10-no-replace-brewer.png' width='100%'></object>

Interestingly, it's still not exactly 'right' in the sense that the eventual proportions in the sample aren't exactly those given in the form of weights. But it's much better at doing this than the current `sample()` method is.

And if we have a sample that is say 25% of the population instead of 50% with `compare_ppswor(n = 5, FUN = sample_unequal, reps = 10000)', then we get results where the proportions and weights are pretty indistinguishable:

<object type="image/svg+xml" data='/img/0276-20-5-no-replace-brewer.svg' width='100%'><img src='/img/0276-20-5-no-replace-brewer.png' width='100%'></object>


{% highlight R lineanchors %}

{% endhighlight %}



{% highlight R lineanchors %}

{% endhighlight %}



{% highlight R lineanchors %}

{% endhighlight %}

